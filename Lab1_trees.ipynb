{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install networkx\n",
    "# !pip install matplotlib\n",
    "# !pip install tqdm\n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install graphviz\n",
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations, groupby\n",
    "\n",
    "from networkx.algorithms import tree\n",
    "from networkx.algorithms import bellman_ford_predecessor_and_distance\n",
    "from networkx.algorithms import floyd_warshall_predecessor_and_distance\n",
    "\n",
    "import numpy.typing as npt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1. Algorithm's analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# You can use this function to generate a random graph with 'num_of_nodes' nodes\n",
    "# and 'completeness' probability of an edge between any two nodes\n",
    "# If 'directed' is True, the graph will be directed\n",
    "# If 'draw' is True, the graph will be drawn\n",
    "def gnp_random_connected_graph(num_of_nodes: int,\n",
    "                               completeness: int,\n",
    "                               directed: bool = False,\n",
    "                               draw: bool = False):\n",
    "    \"\"\"\n",
    "    Generates a random graph, similarly to an Erdős-Rényi\n",
    "    graph, but enforcing that the resulting graph is conneted (in case of undirected graphs)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    if directed:\n",
    "        G = nx.DiGraph()\n",
    "    else:\n",
    "        G = nx.Graph()\n",
    "    edges = combinations(range(num_of_nodes), 2)\n",
    "    G.add_nodes_from(range(num_of_nodes))\n",
    "\n",
    "    for _, node_edges in groupby(edges, key = lambda x: x[0]):\n",
    "        node_edges = list(node_edges)\n",
    "        random_edge = random.choice(node_edges)\n",
    "        if random.random() < 0.5:\n",
    "            random_edge = random_edge[::-1]\n",
    "        G.add_edge(*random_edge)\n",
    "        for e in node_edges:\n",
    "            if random.random() < completeness:\n",
    "                G.add_edge(*e)\n",
    "\n",
    "    for (u,v,w) in G.edges(data=True):\n",
    "        w['weight'] = random.randint(-5, 20)\n",
    "\n",
    "    if draw:\n",
    "        plt.figure(figsize=(10,6))\n",
    "        if directed:\n",
    "            # draw with edge weights\n",
    "            pos = nx.arf_layout(G)\n",
    "            nx.draw(G,pos, node_color='lightblue',\n",
    "                    with_labels=True,\n",
    "                    node_size=500,\n",
    "                    arrowsize=20,\n",
    "                    arrows=True)\n",
    "            labels = nx.get_edge_attributes(G,'weight')\n",
    "            nx.draw_networkx_edge_labels(G, pos,edge_labels=labels)\n",
    "\n",
    "        else:\n",
    "            nx.draw(G, node_color='lightblue',\n",
    "                with_labels=True,\n",
    "                node_size=500)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = gnp_random_connected_graph(10, 1, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kruskal's algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "mstk = tree.minimum_spanning_tree(G, algorithm=\"kruskal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(mstk, node_color='lightblue',\n",
    "        with_labels=True,\n",
    "        node_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mstk.edges(), len(mstk.edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм Крускала шукає кістякове дерево з мінімальною кількістю вершин шляхом пошуку найдешевшого ребра, котре з'єднує ноди, котрі ще не є з'єднаними."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kruskal_mst(G, nvn=None):\n",
    "    if nvn is None:\n",
    "        nodes = [[node] for node in G.nodes]\n",
    "        edges = list(G.edges)\n",
    "    else:\n",
    "        nodes, edges = nvn\n",
    "\n",
    "    min_ = (float(\"inf\"), tuple())\n",
    "    for a,b in edges:\n",
    "        weight = G[a][b]['weight']\n",
    "        if weight < min_[0]:\n",
    "            min_ = (weight, (a,b))\n",
    "\n",
    "    connecting_nodes = []\n",
    "    for i, node in enumerate(nodes):\n",
    "        if min_[1][0] in node or min_[1][1] in node:\n",
    "            connecting_nodes.append(i)\n",
    "\n",
    "    nodes[connecting_nodes[0]] += nodes[connecting_nodes[1]]\n",
    "\n",
    "    del nodes[connecting_nodes[1]]\n",
    "\n",
    "    node = nodes[connecting_nodes[0]]\n",
    "\n",
    "    for edge in edges.copy():\n",
    "        if edge[0] in node and edge[1] in node:\n",
    "            edges.remove(edge)\n",
    "\n",
    "    if len(nodes) == 1:\n",
    "        return [min_[1]]\n",
    "    else:\n",
    "        return sorted([min_[1]] + kruskal_mst(G, (nodes, edges)))\n",
    "\n",
    "kruskal_mst(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prim's algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mstp = tree.minimum_spanning_tree(G, algorithm=\"prim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(mstp, node_color='lightblue',\n",
    "        with_labels=True,\n",
    "        node_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mstp.edges(), len(mstp.edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Алгоритм Прима"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наведено приклад реалізації алгоритму Прима. Він дозволяє побудувати мінімальне кістякове дерево зваженого зв’язного неорієнтованого графа.\n",
    "\n",
    "Алгоритм працює за таким принципом:\n",
    "\n",
    "Нехай G – зв’язний зважений граф із nn вершинами та mm ребрами. Виконати такі дії:\n",
    "\n",
    "1. Вибрати ребро e1​, яке має в графі G найменшу вагу.\n",
    "2. Послідовно визначити ребра e2​,e3​,…,en−1​, на кожному кроці *обираючи ребро з найменшою вагою*, **інцидентне вершині побудованого дерева, таке, що не утворює простих циклів із уже вибраними ребрами**.\n",
    "\n",
    "Отримане дерево T із множиною ребер E(T)={e1​,e2​,e3​,…,en−1​} є *мінімальним кістяковим деревом графа* G.\n",
    "\n",
    "Реалізація алгоритму виводить пари вершин ребер у *форматі (v1​,v2​), де v1 і v2 – вершини графа* та утворюють мінімальне кістякове дерево. Вивід відсортовано в порядку зростання для зручності читання."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prim_mst(G):\n",
    "    start_node = list(G.nodes())[0]\n",
    "    mst_edges = []\n",
    "    visited = set([start_node])\n",
    "    potential_edges = []\n",
    "\n",
    "    for neighbor, info in G[start_node].items():\n",
    "        potential_edges.append((info['weight'], start_node, neighbor))\n",
    "\n",
    "    while potential_edges:\n",
    "        potential_edges.sort(key=lambda x: x[0])\n",
    "\n",
    "        weight, node_1, node_2 = potential_edges.pop(0)\n",
    "\n",
    "        if node_2 not in visited:\n",
    "            visited.add(node_2)\n",
    "            mst_edges.append((node_1, node_2))\n",
    "            for neighbor, info in G[node_2].items():\n",
    "                if neighbor not in visited:\n",
    "                    potential_edges.append((info['weight'], node_2, neighbor))\n",
    "\n",
    "    return sorted(mst_edges)\n",
    "\n",
    "print(prim_mst(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = gnp_random_connected_graph(10, 0.5, True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bellman-Ford algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred is a dictionary of predecessors, dist is a dictionary of distances\n",
    "try:\n",
    "    pred, dist = bellman_ford_predecessor_and_distance(G, 0)\n",
    "    for k, v in dist.items():\n",
    "        print(f\"Distance to {k}:\", v)\n",
    "except:\n",
    "    print(\"Negative cycle detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритм Беллмана — Форда"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Алгоритм Беллмана—Форда** – алгоритм знаходження найкоротших шляхів у зваженому орієнтованому графі. Він визначає найкоротші відстані від початкової вершини до всіх інших, у тому числі якщо граф містить ребра з від’ємною вагою.\n",
    "\n",
    "Алгоритм також дозволяє виявити наявність від’ємних циклів – у такому разі пошук шляхів стає неможливим.\n",
    "\n",
    "Вивід алгоритму – словник, де ключем є вершина, а значенням – мінімальна вага шляху від початкової вершини. Якщо граф містить від’ємний цикл, повертається відповідне повідомлення."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bellman_ford(G, start_node):\n",
    "    distance = {node: float('inf') for node in G.nodes()}\n",
    "    distance[start_node] = 0\n",
    "\n",
    "    for _ in range(len(G.nodes()) - 1):\n",
    "        for u in G.nodes():\n",
    "            for v in G.neighbors(u):\n",
    "                weight = G.get_edge_data(u, v).get('weight', float(\"inf\"))\n",
    "                if distance[u] + weight < distance[v]:\n",
    "                    distance[v] = distance[u] + weight\n",
    "\n",
    "\n",
    "    for u in G.nodes():\n",
    "        for v in G.neighbors(u):\n",
    "            weight = G.get_edge_data(u, v).get('weight', float(\"inf\"))\n",
    "            if distance[u] + weight < distance[v]:\n",
    "                return \"Negative cycle detected\"\n",
    "\n",
    "    return distance\n",
    "\n",
    "print(bellman_ford(G, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Floyd-Warshall algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred is a dictionary of predecessors, dist is a dictionary of distances dictionaries\n",
    "try:\n",
    "    pred, dist = floyd_warshall_predecessor_and_distance(G)\n",
    "    for k, v in dist.items():\n",
    "        print(f\"Distances with {k} source:\", dict(v))\n",
    "except:\n",
    "    print(\"Negative cycle detected\")\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм Флойда-Воршала, котрий шукає найкоротший шлях від однієї вершини до іншої шляхом постійного перебору і порівняння ваг шляхів з довжиною від 1 до n, де n - кількість вершин."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def floyd(G):\n",
    "    nodes = list(G.nodes)\n",
    "    pred = dict( [(node, dict([(node2, node)for node2 in G.nodes])) for node in G.nodes])\n",
    "\n",
    "    dist = {}\n",
    "    for node in nodes:\n",
    "        dist[node] = {}\n",
    "        for other_node in nodes:\n",
    "            if node == other_node:\n",
    "                dist[node][other_node] = 0\n",
    "            elif G.has_edge(node, other_node):\n",
    "                dist[node][other_node] = G[node][other_node]['weight']\n",
    "            else:\n",
    "                dist[node][other_node] = float('inf')\n",
    "\n",
    "    for k in nodes:\n",
    "        for i in nodes:\n",
    "            for j in nodes:\n",
    "                from_k = dist[i][k] + dist[k][j]\n",
    "                if from_k < dist[i][j]:\n",
    "                    dist[i][j] = from_k\n",
    "                    pred[i][j] = k\n",
    "\n",
    "    for i in nodes:\n",
    "        if dist[i][i] < 0:\n",
    "            raise ValueError(\"negative cicle detected -_-\")\n",
    "    return pred, dist\n",
    "\n",
    "floyd(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some useful explanations\n",
    "### How to get list of edges for your algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = list(G.edges()) # by default G.edges are EdgesView class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To get edges with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = list(G.edges(data=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = list(G.nodes())\n",
    "print(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example on time measuring\n",
    "\n",
    "Read more on this: https://realpython.com/python-timer/\n",
    "\n",
    "Recall that you should measure times for 5, 10, 20, 50, 100, 200, 500 nodes 1000 times (and take mean of time taken for each node amount).\n",
    "\n",
    "Then you should build the plot for two algorithms (x - data size, y - mean time of execution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допоміжна функція для вимірювання часу виконання алгоритму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure(func, *args, **kwargs):\n",
    "    start = time.time()\n",
    "    func(*args, **kwargs)\n",
    "    end = time.time()\n",
    "\n",
    "    return end-start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вимірювання часу виконання алгоритму Прима."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_ITERATIONS = 1000\n",
    "time_taken = {'etalon':{}, 'reality': {}}\n",
    "\n",
    "\n",
    "for count in (5, 10, 20, 50, 100):\n",
    "    for i in tqdm(range(NUM_OF_ITERATIONS)):\n",
    "\n",
    "        G = gnp_random_connected_graph(count, 0.4, False)\n",
    "\n",
    "        time_taken['etalon'][count] = measure(tree.minimum_spanning_tree, G, algorithm=\"prim\")\n",
    "        time_taken['reality'][count] = measure(prim_mst, G)\n",
    "\n",
    "plt.plot(time_taken['etalon'].values(), time_taken['etalon'].keys(), label=\"etalon\", color=\"b\", linestyle=\"-\")\n",
    "plt.plot(time_taken['reality'].values(), time_taken['reality'].keys(), label=\"reality\", color=\"g\", linestyle=\"-\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"count_of_nodes\")\n",
    "plt.title(\"Prim\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вимірювання часу виконання алгоритму Крускала."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count in (5, 10, 20, 50, 100):\n",
    "    for i in tqdm(range(NUM_OF_ITERATIONS)):\n",
    "\n",
    "        G = gnp_random_connected_graph(count, 0.4, False)\n",
    "\n",
    "        time_taken['etalon'][count] = measure(tree.minimum_spanning_tree, G, algorithm=\"kruskal\")\n",
    "        time_taken['reality'][count] = measure(kruskal_mst, G)\n",
    "\n",
    "plt.plot(time_taken['etalon'].values(), time_taken['etalon'].keys(), label=\"etalon\", color=\"b\", linestyle=\"-\")\n",
    "plt.plot(time_taken['reality'].values(), time_taken['reality'].keys(), label=\"reality\", color=\"g\", linestyle=\"-\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"count_of_nodes\")\n",
    "plt.title(\"Kruskal\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вимірювання часу виконання алгоритму Беллмана-Форда."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_ITERATIONS = 1000\n",
    "time_taken = {\"standard\": {}, \"reality\": {}}\n",
    "\n",
    "def measure(func, *args):\n",
    "    start = time.time()\n",
    "    func(*args)\n",
    "    end = time.time()\n",
    "    return end - start\n",
    "\n",
    "for count in (5, 10, 20, 50, 100, 200):\n",
    "    for i in tqdm(range(NUM_OF_ITERATIONS)):\n",
    "        G = gnp_random_connected_graph(count, 0.4, True)\n",
    "        try:\n",
    "            time_taken[\"standard\"][count] = measure(bellman_ford_predecessor_and_distance, G, 0)\n",
    "            time_taken[\"reality\"][count] = measure(bellman_ford, G, 0)\n",
    "        except:\n",
    "            nx.NetworkXUnbounded\n",
    "\n",
    "plt.plot(time_taken['standard'].values(), time_taken['standard'].keys(), label=\"standard\", color=\"b\", linestyle=\"-\")\n",
    "plt.plot(time_taken['reality'].values(), time_taken['reality'].keys(), label=\"reality\", color=\"g\", linestyle=\"-\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"count_of_nodes\")\n",
    "plt.title(\"bellman_ford\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вимірювання часу виконання алгоритму Флойда—Воршелла. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_ITERATIONS = 1000\n",
    "time_taken = {\"standard\": {}, \"reality\": {}}\n",
    "\n",
    "def measure(func, *args):\n",
    "    start = time.time()\n",
    "    func(*args)\n",
    "    end = time.time()\n",
    "\n",
    "    return end - start\n",
    "\n",
    "for count in (5, 10, 20, 50, 100, 200):\n",
    "    for i in tqdm(range(NUM_OF_ITERATIONS)):\n",
    "\n",
    "        G = gnp_random_connected_graph(count, 0.4, True)\n",
    "\n",
    "        time_taken[\"standard\"][count] = measure(floyd_warshall_predecessor_and_distance, G)\n",
    "        time_taken[\"reality\"][count] = measure(floyd, G)\n",
    "\n",
    "\n",
    "plt.plot(time_taken['standard'].values(), time_taken['standard'].keys(), label=\"standard\", color=\"b\", linestyle=\"-\")\n",
    "plt.plot(time_taken['reality'].values(), time_taken['reality'].keys(), label=\"reality\", color=\"g\", linestyle=\"-\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"count_of_nodes\")\n",
    "plt.title(\"floyd_warshall\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реалізовані нами алгоритми як бачимо є значно повільніші. Імовірними причинами є те, що ми використовуємо в своїх реалізаціях лише вбудовані типи даних, а також використовуємо цикли замість рекурсії. А також можливо алгоритми реалізовані нами вирішують задачу більш очевидним способом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Decision Tree Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-learn package\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General idea\n",
    "\n",
    "#### You are expected to write a quite simple, yet good core logic of decision tree classifier class. Additionaly, you need to test your results and write down a report on what you've done, which principles used and explain the general process.\n",
    "\n",
    "#### Hopefully, you have already learned what is decision tree classifier and how it work. For better understanding, and in case if something is still unclear for you, here are some useful links on basics of DTC:\n",
    "- https://www.youtube.com/watch?v=ZVR2Way4nwQ\n",
    "- https://towardsdatascience.com/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e\n",
    "- https://towardsdatascience.com/decision-tree-from-scratch-in-python-46e99dfea775\n",
    "- https://www.kaggle.com/code/prashant111/decision-tree-classifier-tutorial\n",
    "- https://towardsdatascience.com/decision-tree-classifier-explained-in-real-life-picking-a-vacation-destination-6226b2b6057\n",
    "\n",
    "#### Also, for those interested to learn more about machine learning and particulary Desicion Trees - here is a great course on Coursera (you may be interested in the whole course or just this particular week):\n",
    "- https://www.coursera.org/learn/advanced-learning-algorithms/home/week/4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset\n",
    "#### You can use Iris dataset for this task. It is a very popular dataset for machine learning and data science. It contains 150 samples of 3 different species of Iris flowers (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters. \n",
    "Read more on this: https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html\n",
    "https://en.wikipedia.org/wiki/Iris_flower_data_set\n",
    "#### However, using more interesting and intricate datasets is much appreciated. You can use any dataset you want, but it should be a classification one. For example you can use breast cancer or wine datasets, which are also available in sklearn.datasets. Or you can use any other dataset you find interesting.\n",
    "P.S. In case you are not sure if your dataset is suitable, feel free to ask assistants :)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "iris = load_iris()\n",
    "dir(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that we have 150 entries (samples, infos about a flower). The columns being: Sepal Length, Sepal Width, Petal Length and Petal Width(features). Let's look at first two entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.data[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To undestand data little bit better, let's plot some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "y = iris.target\n",
    "\n",
    "plt.figure(2, figsize=(8, 6))\n",
    "plt.clf()\n",
    "\n",
    "# Plot the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Set1, edgecolor=\"k\")\n",
    "plt.xlabel(\"Sepal length\")\n",
    "plt.ylabel(\"Sepal width\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can clearly see, that even basing on those two parameters, we can clearly divide (classify) out data into several groups. For this, we will use decision tree classifier: https://scikit-learn.org/stable/modules/tree.html#tree\n",
    "\n",
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "\n",
    "### Example of usage\n",
    "\n",
    "\n",
    "**Decision Trees (DTs) are a non-parametric supervised learning method used for classification and regression**. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features. A tree can be seen as a piecewise constant approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = DecisionTreeClassifier()\n",
    "\n",
    "X, y = iris.data, iris.target\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / test split\n",
    "\n",
    "We train our model using training dataset and evaluate its performance basing on the test dataset. Reason to use two separate datasets is that our model learns its parameters from data, thus test set allows us to check its possibilities on completely new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(X, y, test_size= 0.20)\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model learning\n",
    "\n",
    "It learns its parameters (where it should split data and for what threshold value) basing on the training dataset. It is done by minimizing some cost function (e.g. Gini impurity or entropy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of produced tree\n",
    "\n",
    "You do not need to understand this piece of code :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "dot_data = tree.export_graphviz(clf, out_file=None)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(clf, out_file=None,\n",
    "                     feature_names=iris.feature_names,\n",
    "                     class_names=iris.target_names,\n",
    "                     filled=True, rounded=True,\n",
    "                     special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction step\n",
    "\n",
    "Now we can use our model to predict which type has a flower, basing on its parameters.\n",
    "\n",
    "This is conducted basically via traversing the tree that you can see above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also measure the accuracy of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(predictions == y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get clearer intuition about predicion, let's look at those X, that should be labeled to some flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here you can traverse the tree above by yourself and make sure that prediction works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict([X_test[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, it is your turn to write such classifier by yourself!\n",
    "\n",
    "####  Gini impurity\n",
    "\n",
    "Decision trees use the concept of Gini impurity to describe how “pure” a node is. A node is pure (G = 0) if all its samples belong to the same class, while a node with many samples from many different classes will have a Gini closer to 1.\n",
    "\n",
    "$G = 1 - \\sum_{k=1}^{n}p_{k}^2$\n",
    "\n",
    "For example, if a node contains five samples, with two belonging to the first class (first flower), two of class 2, one of class 3 and none of class 4, then\n",
    "\n",
    "$G = 1 - (\\frac{2}{5})^2 - (\\frac{2}{5})^2 - (\\frac{1}{5})^2 = 0.64$\n",
    "\n",
    "#### Remarks \n",
    "- We recommend using additional functions in `DecisionTreeClassifier` class, to make the implementation process easier.\n",
    "- [use this hint](https://arc.net/l/quote/pqvyjqei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Node:\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, class_= None):\n",
    "        \"\"\"\n",
    "        :param X: numpy array of form [[feature1,feature2, ... featureN], ...] (i.e. [[1.5, 5.4, 3.2, 9.8] , ...] for case with iris d.s.)\n",
    "        :param y: numpy array of from [class1, class2, ...] (i.e. [0,1,1,2,1,0,...] for case with iris d.s.)\n",
    "        \"\"\"\n",
    "\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.class_ = class_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth: int) -> None:\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "        self.number_of_classes = None\n",
    "\n",
    "    def fit(self, X: npt.NDArray, y: npt.NDArray) -> None:\n",
    "        \"\"\"\n",
    "        Basically, function that performs all the training (building of a tree)\n",
    "        We recommend to use it as a wrapper of recursive building function\n",
    "        \"\"\"\n",
    "        self.number_of_classes = np.unique(y).size\n",
    "        self.tree = self.__build_tree(X, y)\n",
    "\n",
    "    def __build_tree(self, X, y, depth=0):\n",
    "        if depth >= self.max_depth or len(set(y)) == 1:\n",
    "            return Node(class_=np.bincount(y).argmax())\n",
    "\n",
    "        feature, threshold = self.__split(X, y)\n",
    "\n",
    "        left = X[:, feature] < threshold\n",
    "        right = ~left\n",
    "        left_tree = self.__build_tree(X[left], y[left], depth + 1)\n",
    "        right_tree = self.__build_tree(X[right], y[right], depth + 1)\n",
    "\n",
    "        return Node(feature, threshold, left_tree, right_tree)\n",
    "\n",
    "    def __split(self, X, y):\n",
    "        best_gini = float('inf')\n",
    "        best_feature, best_threshold = None, None\n",
    "\n",
    "        for feature in range(X.shape[1]):\n",
    "            coords = np.unique(X[:, feature])\n",
    "            for coord in coords:\n",
    "                left = X[:, feature] < coord\n",
    "                right = ~left\n",
    "                gini = self.__gini(y[left], y[right])\n",
    "\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_feature = feature\n",
    "                    best_threshold = coord\n",
    "\n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def __gini(self, left, right):\n",
    "        def gini(side):\n",
    "            counts = np.bincount(side, minlength=self.number_of_classes)\n",
    "            if counts.sum() == 0:\n",
    "                return 0\n",
    "            probs = counts / counts.sum()\n",
    "            return 1 - np.sum(probs ** 2)\n",
    "\n",
    "        total = len(left)+len(right)\n",
    "\n",
    "        if total == 0:\n",
    "            return 1\n",
    "\n",
    "        return (len(left)/total)*gini(left) + (len(right)/total)*gini(right)\n",
    "\n",
    "    def predict(self, X_test: npt.NDArray) -> list:\n",
    "        \"\"\"\n",
    "        Traverse the tree while there is a child\n",
    "        and return the predicted class for it\n",
    "        \"\"\"\n",
    "        prediction = [self.__step_in_tree(self.tree, X) for X in X_test]\n",
    "        return prediction\n",
    "\n",
    "    def __step_in_tree(self, node, X):\n",
    "        if node.class_ is not None:\n",
    "            return node.class_\n",
    "        if X[node.feature_index] < node.threshold:\n",
    "            return self.__step_in_tree(node.left, X)\n",
    "        else:\n",
    "            return self.__step_in_tree(node.right, X)\n",
    "\n",
    "dtc = DecisionTreeClassifier(3)\n",
    "X, y = iris.data, iris.target\n",
    "dtc.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(X_test: list[list], y_test: list) -> float:\n",
    "    \"\"\"\n",
    "    Returns accuracy of the model (ratio of right guesses to the number of samples)\n",
    "    \"\"\"\n",
    "    predicrion = dtc.predict(X_test)\n",
    "    corrrect = sum(p == y for p, y in zip(predicrion, y_test))\n",
    "\n",
    "    return corrrect / len(y_test)\n",
    "\n",
    "evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
